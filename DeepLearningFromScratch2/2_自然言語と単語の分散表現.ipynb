{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_自然言語と単語の分散表現.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nepptumsat/nlp/blob/master/DeepLearningFromScratch2/2_%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E3%81%A8%E5%8D%98%E8%AA%9E%E3%81%AE%E5%88%86%E6%95%A3%E8%A1%A8%E7%8F%BE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITTcykBKLVEL",
        "colab_type": "text"
      },
      "source": [
        "# 2.1 自然言語処理とは\n",
        "\n",
        "　日本語や英語など、私たちが普段使っている言葉を**自然言語（Natural Language）**という。また、**自然言語処理（Natural Language Proccessing : NLP）**とは、文字通り解釈すれば「自然言語を処理する分野」ということになる。分かりやすくいうと、「私たちの言葉をコンピュータに理解させるための技術（分野）」といえる。\n",
        "   \n",
        "   \n",
        "　コンピュータが理解できる言語というと、「マークアップ言語」や「プログラミング言語」などが思い浮かべられるが、これらは一意に決まったルールが定められており、\"固い言語\"であるといえる。一方、私たちが普段使っている日本語や英語などの自然言語は、\"柔らかい言語\"であるといえる。これは同じ意味の単語や文章でも様々な表現が可能であったり、文章に曖昧さがあったりと、柔軟に意味や形が変わることを意味する。\n",
        "  \n",
        "頭の固いコンピュータに自然言語を理解させることは一筋縄ではいかない。しかし、その難問をクリアできればとても役に立つものを生み出すことができる。実際の例として、文章の自動要約、質問応答システム、感情分析、自動翻訳などがある。私たちの身の回りには既に、たくさんの自然言語処理の技術が使われている。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtMaBNTmPFx6",
        "colab_type": "text"
      },
      "source": [
        "## 2.1.1 単語の意味\n",
        "　私たちの言葉は「文字」によって構成される。そして、言葉の意味は「単語」によって構成される。単語は言ってみれば意味の最小単位であり、「単語の意味」を理解させることが重要であるといえる。\n",
        "   \n",
        "　本章のテーマは「単語の意味」を理解させることである。「単語の意味」の表現方法として、具体的には、本章と次章で以下の３つを挙げる。\n",
        " \n",
        " - シソーラスによる手法\n",
        " - カウントベースの手法\n",
        " - 推論ベースの手法\n",
        " \n",
        " 最初に、人の手によって作られたシソーラス（類語辞書）を利用する手法について見ていく。次に、統計情報から単語を表現するカウントベースの手法について学習する。そして最後に推論ベースの手法（具体的にはword2vecと呼ばれる手法）を扱う。\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsiiaJEZS8Rs",
        "colab_type": "text"
      },
      "source": [
        "# 2.2 シソーラス\n",
        "　「単語の意味」を表すために、人の手によって単語の意味を定義することが考えられる。「広辞苑」などの辞書のように、何か一つの単語に対して、その単語の意味を説明していくような考えである。\n",
        "\n",
        "　自然言語処理の歴史を振り返ると、**シソーラス（thesaurus）**と呼ばれるタイプの辞書が多く使われてきた。シソーラスは基本的には類語辞書であり、ある単語に対する「同義語」や「類義語」が同じグループに分類される。例えば、car\n",
        "のシソーラスは以下のようになる。\n",
        "\n",
        "---\n",
        " \n",
        "*car* = *auto*, *automobile*, *machine*, *motorcar*\n",
        "\n",
        "---\n",
        "\n",
        "　また、自然言語処理において利用されるシソーラスでは、単語の間で、「上位と下位」、「全体と部分」などの関連性が定義されている場合がある。具体的には、以下のように、グラフ構造によって関連性が定義されている場合などである\n",
        "。\n",
        " \n",
        " <div drawio-diagram=\"77\"><img src=\"http://wiki.nepp.tokyo:8080/uploads/images/drawio/2019-06-Jun/Drawing-Kushiro-Taichi-1560774581.png\"></div>\n",
        " \n",
        " 　このようにして、全ての単語に類義語の集合を作り、または単語間の関係をグラフで表現することで、単語間の繋がりを定義することができる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeTKYrvyb9UU",
        "colab_type": "text"
      },
      "source": [
        "## 2.2.1 WordNet\n",
        "　自然言語処理の分野において、最も有名なシソーラスは**WordNet**と呼ばれる。すでに様々なアプリケーションで活躍している。\n",
        "　WordNetを用いると、類義語を取得したり、単語ネットワークを用いて類似度の計算等を行うことができる。ここでは、WordNetに関する詳細の説明は行わない。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJXZn5idt7v2",
        "colab_type": "text"
      },
      "source": [
        "## 2.2.2 シソーラスの問題点\n",
        "WordNetのようなシソーラスでは、人の手によってラベルづけを行うことによる欠点が存在する。以下に、それらをまとめる\n",
        "\n",
        "**時代の変化に対応するのが困難**  \n",
        "同じ単語でも時代によって意味が変化する場合がある。  \n",
        "  \n",
        "**人の作業コストが高い**  \n",
        "シソーラスの作成に、とても大きな人的コストが発生する。  \n",
        "  \n",
        "**単語の細かなニュアンスを表現できない**  \n",
        "「レトロ」と「ヴィンテージ」のように、単語の意味はほとんど一緒でも、微妙なニュアンスの違いがある場合、その差異を表現できない。  \n",
        "\n",
        "\n",
        "このような問題を避けるために、「カウントベースの手法」と「推論ベースの手法」へと進む。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fq4_hNnze5g",
        "colab_type": "text"
      },
      "source": [
        "# 2.3 カウントベースの手法\n",
        "　カウントベースの手法には**コーパス（corpus）**を利用する。コーパスとは簡単にいうと大量のテキストデータのことである。やみくもに集められたデータではなく、自然言語処理のために用意されたテキストデータを一般に「コーパス」と呼ぶ。  \n",
        " 　コーパスは人の手によって書かれたものであり、自然言語に対する人の”知識”が含まれている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-feeQgB0a4v",
        "colab_type": "text"
      },
      "source": [
        "## 2.3.1 Pythonによるコーパスの下準備\n",
        "　有名なコーパスとして、WikipediaやGoogle Newsなどがある。ここからはPythonを使ってとても小さなテキストデータの前処理を行う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ2OP2sS0bwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = 'You say goodbye and I say hello.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXPsZZam0_jQ",
        "colab_type": "text"
      },
      "source": [
        "前処理として、大文字を小文字に変換し単語ごとに分割する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz5maOzj07yc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9dbe0344-e4bc-4cd9-ac05-97953c3401bb"
      },
      "source": [
        "text = text.lower()\n",
        "text = text.replace('.', ' .')\n",
        "text"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'you say goodbye and i say hello .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjq-vABC1W1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cf4b781-cea0-45ba-92ca-bb1f32281fb2"
      },
      "source": [
        "words = text.split(' ')\n",
        "words"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S02wHei1j-6",
        "colab_type": "text"
      },
      "source": [
        "次に単語に対するid付けを行う。idから単語、単語からidへの変換を行うための辞書を用意する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhL2j7Ca1b6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_id = {}\n",
        "id_to_word = {}\n",
        "\n",
        "for word in words:\n",
        "    if word not in word_to_id:\n",
        "        new_id = len(word_to_id)\n",
        "        word_to_id[word] = new_id\n",
        "        id_to_word[new_id] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7mqcEtI2KBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9bf7daf-7e2e-4757-c1a7-3fbf12246f1f"
      },
      "source": [
        "word_to_id"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 6, 'and': 3, 'goodbye': 2, 'hello': 5, 'i': 4, 'say': 1, 'you': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc8pNdjQ2LZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf0e1325-cc26-4037-8b01-bb222179ce12"
      },
      "source": [
        "id_to_word"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-JBHOgV2Uvn",
        "colab_type": "text"
      },
      "source": [
        "最後に単語のリストから単語idのリストを生成する。ここでは、Numpy配列を用いる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W03N6XlI2MwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f88228b-019f-4474-97d8-48a45319ce7f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "corpus = [word_to_id[w] for w in words]\n",
        "corpus = np.array(corpus)\n",
        "corpus"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 1, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0BGXvj620gb",
        "colab_type": "text"
      },
      "source": [
        "ここまでの前処理を一つの関数にまとめる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwDRHgXs2zkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = text.replace('.', ' .')\n",
        "    words = text.split(' ')\n",
        "    \n",
        "    word_to_id = {}\n",
        "    id_to_word = {}\n",
        "    for word in words:\n",
        "        if word not in word_to_id:\n",
        "            new_id = len(word_to_id)\n",
        "            word_to_id[word] = new_id\n",
        "            id_to_word[new_id] = word\n",
        "    \n",
        "    corpus = np.array([word_to_id[w] for w in words])\n",
        "    \n",
        "    return corpus, word_to_id, id_to_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHAiz3HK3q2w",
        "colab_type": "text"
      },
      "source": [
        "ここで前処理を行った、corpus、word_to_id、id_to_wordは今後も頻繁に用いる。次に紹介する「カウントベースの手法」によって、単語をベクトルで表す。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OFKiAwp4GkS",
        "colab_type": "text"
      },
      "source": [
        "## 2.3.2 単語の分散表現\n",
        "　色はRGBを用いると３次元のベクトルで正確に情報を表すことができる。できる限りコンパクトで理にかなったベクトル表現を「単語」でもできないだろうか？これから「単語の意味」を的確に捉えたベクトル表現を目指す。これを自然言語処理の分野では**分散表現**と呼ぶ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_v5aOsC7rgq",
        "colab_type": "text"
      },
      "source": [
        "## 2.3.3 分布仮説\n",
        "　自然言語処理の歴史において、単語ベクトルで表すための研究を見ていくと、重要な手法のほとんどがあるシンプルなアイディアに基づいている。それは、「単語の意味は周囲の単語によって形成される」というものである。これは、**分布仮説**と呼ばれ、最近の研究の多くもこの仮説に基づいている。分布仮説はの考え方は、単語自体に意味はなくその単語の「コンテキスト（文脈）」によって単語の意味が形成されるという考え方である。  \n",
        "　本テキストでは、これから先「コンテキスト」という言葉を用いる場合、ある単語の周囲に存在する単語を指す。  そして、どのくらいの範囲の周囲の単語を「コンテキスト」として扱うかのコンテキストのサイズのことを「ウインドウサイズ（window size）」という言葉で表すことにする。例えば、ウインドウサイズが１の場合は左右の１単語、2の場合は左右の２単語といったようになる。\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRVVvu8Z92PA",
        "colab_type": "text"
      },
      "source": [
        "## 2.3.4 共起行列\n",
        "　分布仮説に基づいて単語をベクトルで表していく。そのための一番素直な方法は、周囲の単語を\"カウント\"することである。ここではこの方法を「カウントベースの手法」と呼ぶ。  \n",
        "　ここから実際にカウントベースの手法を実装していく。まずは前処理を行う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUDPVJy391db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aTIGHLO7gnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68f8e133-d451-467c-cfa6-9762b7ef6f0c"
      },
      "source": [
        "print(corpus)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 1 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQMXFq57_EhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75c6f76b-a319-4eb7-a265-1a86e5339929"
      },
      "source": [
        "print(id_to_word)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbjLAlc2KqG2",
        "colab_type": "text"
      },
      "source": [
        "上記の結果より、語彙数は７個あることがわかる。ここでは、ウインドウサイズを１としてコンテキストに含まれる単語の頻度を数えていく。例えば、単語idが０の「you」のコンテキストには、「say」が１つだけ存在する。これをテーブルで表すと以下のようになる。\n",
        "\n",
        "| |you|say|goodbye|and|i|hello|.|\n",
        "|-:|-:|-:|-:|-:|-:|-:|-:|\n",
        "|you|0|1|0|0|0|0|0|\n",
        "\n",
        "続いて、単語idが１の「say」について調べる。そうすると以下のような結果となる。\n",
        "\n",
        "| |you|say|goodbye|and|i|hello|.|\n",
        "|-:|-:|-:|-:|-:|-:|-:|-:|\n",
        "|say|1|0|1|0|1|1|0|\n",
        "\n",
        "全ての単語に対し、以上の操作を行うと以下のようなの表が出来上がる。\n",
        "\n",
        "| |you|say|goodbye|and|i|hello|.|\n",
        "|-:|-:|-:|-:|-:|-:|-:|-:|\n",
        "|you|0|1|0|0|0|0|0|\n",
        "|say|1|0|1|0|1|1|0|\n",
        "|goodbye|0|1|0|1|0|0|0|\n",
        "|and|0|0|1|0|1|0|0|\n",
        "|i|0|1|0|1|0|0|0|\n",
        "|hello|0|1|0|0|0|0|1|\n",
        "|.|0|0|0|0|0|1|0|\n",
        "\n",
        "このようなテーブルは**共起行列（co-occurence matrix）**と呼ばれる。今回の共起行列を実際にpythonで作成してみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gXg895VNTBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = np.array([\n",
        "    [0, 1, 0, 0, 0, 0, 0],\n",
        "    [1, 0, 1, 0, 1, 1, 0],\n",
        "    [0, 1, 0, 1, 0, 0, 0],\n",
        "    [0, 0, 1, 0, 1, 0, 0],\n",
        "    [0, 1, 0, 1, 0, 0, 0],\n",
        "    [0, 1, 0, 0, 0, 0, 1],\n",
        "    [0, 0, 0, 0, 0, 1, 0],\n",
        "], dtype=np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO8CqV6BNuiU",
        "colab_type": "text"
      },
      "source": [
        "共起行列を手作業で作成するのは大変であるため、コーパスから共起行列を自動で作成する関数を実装する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4cNC5oVNt0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
        "    corpus_size = len(corpus)\n",
        "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
        "    \n",
        "    for idx, word_id in enumerate(corpus):\n",
        "        for i in range(1, window_size + 1):\n",
        "            left_idx = idx - i\n",
        "            right_idx = idx + i\n",
        "            \n",
        "            if left_idx >= 0:\n",
        "                left_word_id = corpus[left_idx]\n",
        "                co_matrix[word_id, left_word_id] += 1\n",
        "            \n",
        "            if right_idx < corpus_size:\n",
        "                right_word_id = corpus[right_idx]\n",
        "                co_matrix[word_id, right_word_id] += 1\n",
        "    \n",
        "    return co_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IK4t8JhOEvt",
        "colab_type": "text"
      },
      "source": [
        "これ以降、この関数を使ってコーパスの共起行列を作成する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI-CpyJ6NlLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}